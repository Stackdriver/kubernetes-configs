# THIS FILE IS AUTO-GENERATED DO NOT EDIT
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    k8s-app: stackdriver-heapster
    version: v1.6.1
  name: heapster
  namespace: stackdriver-agents
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: stackdriver-heapster
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        k8s-app: stackdriver-heapster
        version: v1.6.1
    spec:
      containers:
      - env:
        - name: CLUSTER_NAME
          valueFrom:
            configMapKeyRef:
              name: cluster-config
              key: cluster_name
        - name: CLUSTER_LOCATION
          valueFrom:
            configMapKeyRef:
              name: cluster-config
              key: cluster_location
        - name: GOOGLE_APPLICATION_CREDENTIALS
          valueFrom:
            configMapKeyRef:
              name: google-cloud-config
              key: credentials_path
        command:
        - /heapster
        - --source=kubernetes.summary_api:''
        - --sink=stackdriver:?cluster_name=$(CLUSTER_NAME)&cluster_location=$(CLUSTER_LOCATION)&zone=$(CLUSTER_LOCATION)&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110
        image: gcr.io/stackdriver-agents/heapster-amd64:v1.6.1
        imagePullPolicy: Always
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 8082
            scheme: HTTP
          initialDelaySeconds: 180
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: heapster
        resources:
          limits:
            cpu: 88m
            memory: 204Mi
          requests:
            cpu: 88m
            memory: 204Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /etc/google-cloud/
          name: google-cloud-config
      - command:
        - /pod_nanny
        - --cpu=80m
        - --extra-cpu=0.5m
        - --memory=140Mi
        - --extra-memory=4Mi
        - --threshold=5
        - --deployment=heapster
        - --container=heapster
        - --poll-period=300000
        - --estimator=exponential
        env:
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        image: gcr.io/google_containers/addon-resizer:1.7
        imagePullPolicy: IfNotPresent
        name: heapster-nanny
        resources:
          limits:
            cpu: 50m
            memory: 112360Ki
          requests:
            cpu: 50m
            memory: 112360Ki
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: heapster
      serviceAccountName: heapster
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          defaultMode: 420
          name: google-cloud-config
        name: google-cloud-config

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: stackdriver-log-aggregator
  namespace: stackdriver-agents
  labels:
    app: stackdriver-log-aggregator
    cluster-level: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stackdriver-log-aggregator
      cluster-level: "true"
  template:
    metadata:
      labels:
        app: stackdriver-log-aggregator
        cluster-level: "true"
    spec:
      containers:
      - name: stackdriver-log-aggregator
        image: us.gcr.io/stackdriver-kubernetes-1337/stackdriver-logging-agent:20190314-1
        imagePullPolicy: IfNotPresent
        env:
        - name: GOOGLE_APPLICATION_CREDENTIALS
          valueFrom:
            configMapKeyRef:
              name: google-cloud-config
              key: credentials_path
        - name: CLUSTER_NAME
          valueFrom:
            configMapKeyRef:
              name: cluster-config
              key: cluster_name
        - name: CLUSTER_LOCATION
          valueFrom:
            configMapKeyRef:
              name: cluster-config
              key: cluster_location
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - |
              LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/k8s-fluentd-buffers ]; then
                exit 1;
              fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [[ -z "$(find /var/log/k8s-fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]]; then
                rm -rf /var/log/fluentd-buffers;
                exit 1;
              fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [[ -z "$(find /var/log/k8s-fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]]; then
                exit 1;
              fi;
          failureThreshold: 3
          initialDelaySeconds: 600
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            cpu: 8000m
            memory: 8000Mi
          requests:
            cpu: 2000m
            memory: 1000Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        ports:
        - containerPort: 8989
          hostPort: 8989
          protocol: TCP
        volumeMounts:
        - mountPath: /var/log
          name: varlog
        - mountPath: /etc/google-fluentd/google-fluentd.conf
          subPath: google-fluentd.conf
          name: output-config-volume
        - mountPath: /etc/google-fluentd/config.d
          name: input-config-volume
        - mountPath: /etc/google-cloud/
          name: google-cloud-config
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      tolerations:
      - operator: "Exists"
        effect: "NoExecute"
      - operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - hostPath:
          path: /var/log
          type: ""
        name: varlog
      - configMap:
          defaultMode: 420
          name: stackdriver-log-aggregator-output-config
        name: output-config-volume
      - configMap:
          defaultMode: 420
          name: stackdriver-log-aggregator-input-config
        name: input-config-volume
      - configMap:
          defaultMode: 420
          name: google-cloud-config
        name: google-cloud-config
  strategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: stackdriver-log-aggregator-input-config
  namespace: stackdriver-agents
data:
  forward.input.conf: |-
    <source>
      @type forward
      port 8989
      bind 0.0.0.0
    </source>

    <match k8s_container.**>
      @type record_modifier
      <record>
        # Extract local_resource_id from record["kubernetes"] for
        # 'k8s_container' monitored resource. The format is:
        # 'k8s_container.<namespace_name>.<pod_name>.<container_name>'.
        "logging.googleapis.com/local_resource_id" ${"k8s_container.#{record["kubernetes"]["namespace_name"]}.#{record["kubernetes"]["pod_name"]}.#{record["kubernetes"]["container_name"]}"}
        # - Rename 'log' field to the more generic 'message'. This lets the
        # fluent-plugin-google-cloud know to flatten the field as 'textPayload'
        # instead of 'jsonPayload' after extracting 'time', 'severity' and
        # 'stream' from the record.
        # - Trim the entries which exceed 100KB to avoid dropping them, since
        # Stackdriver only supports entries that are up to 100KB in size.
        message ${record['log'].length > 100000 ? "[Trimmed]#{record['log'][0..100000]}..." : record['log']}
        # If 'severity' is not set, assume stderr is ERROR and stdout is INFO.
        severity ${record['severity'] || if record['stream'] == 'stderr' then 'ERROR' else 'INFO' end}
        # Extract "kubernetes"->"labels" and set them as
        # "logging.googleapis.com/labels". Prefix these labels with "k8s-pod/"
        # to distinguish with other labels and avoid label name collision with
        # other types of labels.
        _dummy_labels_ ${if record.is_a?(Hash) && record.has_key?('kubernetes') && record['kubernetes'].has_key?('labels') && record['kubernetes']['labels'].is_a?(Hash); then; record["logging.googleapis.com/labels"] = record['kubernetes']['labels'].map{ |k, v| ["k8s-pod/#{k}", v]}.to_h; end; nil}
        # TODO: Parse 'source' from glog lines either here or in the forwarder.
        # Parse the 'source' field created for glog lines into a single
        # top-level field, for proper processing by the output plugin.
        # For example, if a record includes:
        #     {"source":"handlers.go:131"},
        # then the following entry will be added to the record:
        #     {"logging.googleapis.com/sourceLocation":
        #          {"file":"handlers.go", "line":"131"}
        #     }
        _dummy_source_location_ ${if record.is_a?(Hash) && record.has_key?('source') && record['source'].include?(':'); then; source_parts = record['source'].split(':', 2); record['logging.googleapis.com/sourceLocation'] = {'file' => source_parts[0], 'line' => source_parts[1]} else; nil; end}
      </record>
      tag ${if record['stream'] == 'stderr' then 'stderr' else 'stdout' end}
      remove_keys kubernetes,log,stream,_dummy_labels_,_dummy_source_location_
    </match>

    # Add a unique insertId to each log entry that doesn't already have it.
    # This helps guarantee the order and prevent log duplication.
    <filter **>
      @type add_insert_ids
    </filter>
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: stackdriver-log-aggregator-output-config
  namespace: stackdriver-agents
data:
  google-fluentd.conf: |-
    @include config.d/*.conf

    <system>
      workers 20
      root_dir /var/log/fluentd
    </system>

    # Do not collect fluentd's own logs to avoid infinite loops.
    <match fluent.**>
      @type null
    </match>

    <match **>
      #@type file
      #path /var/log/fluentd/file.%Y%m%d
      @type google_cloud
      @id google_cloud

      # Try to detect JSON formatted log entries.
      detect_json true
      # Allow log entries from multiple containers to be sent in the same
      # request.
      split_logs_by_tag false
      <buffer>
        # Set the buffer type to file to improve the reliability and reduce the
        # memory consumption.
        @type file
        # The max size of each chunks: events will be written into chunks until
        # the size of chunks become this size
        # Set the chunk limit conservatively to avoid exceeding the recommended
        # chunk size of 5MB per write request.
        chunk_limit_size 512k
        # Limit the number of queued chunks.
        queued_chunks_limit_size 20
        # Block processing of input plugin to emit events into that buffer.
        overflow_action block
        # Never wait more than 5 seconds before flushing logs in the non-error
        # case.
        flush_interval 5s
        # Seconds to wait before next retry to flush.
        retry_wait 5s
        # The base number of exponential backoff for retries.
        retry_exponential_backoff_base 5
        # The maximum interval seconds for exponential backoff between retries
        # while failing.
        retry_max_interval 1200
      </buffer>
      # Use multiple threads for processing.
      num_threads 2
      use_grpc true
      k8s_cluster_name "#{ENV["CLUSTER_NAME"]}"
      k8s_cluster_location "#{ENV["CLUSTER_LOCATION"]}"
      adjust_invalid_timestamps false
    </match>

---
# Log Forwarder (Fluent Bit) DaemonSet to tail log files.
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: stackdriver-log-forwarder
  namespace: stackdriver-agents
  labels:
    app: stackdriver-log-forwarder
spec:
  selector:
    matchLabels:
      app: stackdriver-log-forwarder
  template:
    metadata:
      labels:
        app: stackdriver-log-forwarder
    spec:
      containers:
      - name: stackdriver-log-forwarder
        image: fluent/fluent-bit:1.0.4
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: stackdriver-log-forwarder-config
          mountPath: /fluent-bit/etc/
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      serviceAccountName: stackdriver-log-forwarder
      terminationGracePeriodSeconds: 60
      tolerations:
      - operator: "Exists"
        effect: "NoExecute"
      - operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: stackdriver-log-forwarder-config
        configMap:
          name: stackdriver-log-forwarder-config
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
---
# Log Forwarder (Fluent Bit) configuration map.
apiVersion: v1
kind: ConfigMap
metadata:
  name: stackdriver-log-forwarder-config
  namespace: stackdriver-agents
  labels:
    app: stackdriver-log-forwarder
data:
  # Configuration files: server, input, filters, and output
  # ======================================================
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     warn
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE input-containers.conf
    @INCLUDE input-systemd.conf
    @INCLUDE filter-kubernetes.conf
    @INCLUDE output-fluentd.conf

  input-containers.conf: |
    [INPUT]
        Name               tail
        Tag                k8s_container.*
        Path               /var/log/containers/*.log
        Parser             docker
        DB                 /var/log/fluent-bit-k8s-container.db
        Buffer_Chunk_Size  512KB
        Buffer_Max_Size    5M
        Rotate_Wait        30
        Mem_Buf_Limit      30MB
        Skip_Long_Lines    On
        Refresh_Interval   10

  input-systemd.conf: |
    [INPUT]
        # https://docs.fluentbit.io/manual/input/systemd
        Name            systemd
        Tag             docker
        Path            /var/log/journal
        DB              /var/log/fluent-bit-k8s-node-journald-docker.db
        Systemd_Filter  _SYSTEMD_UNIT=docker.service

    [INPUT]
        # https://docs.fluentbit.io/manual/input/systemd
        Name            systemd
        Tag             kubelet
        Path            /var/log/journal
        DB              /var/log/fluent-bit-k8s-node-journald-kubelet.db
        Systemd_Filter  _SYSTEMD_UNIT=kubelet.service

    [INPUT]
        # https://docs.fluentbit.io/manual/input/systemd
        Name            systemd
        Tag             node-journal
        Path            /var/log/journal
        DB              /var/log/fluent-bit-k8s-node-journald.db

    [FILTER]
        # https://docs.fluentbit.io/manual/filter/grep
        Name     grep
        Match    node-journal
        Exclude  _SYSTEMD_UNIT ^(docker|kubelet)\.service$

    # We have to use a filter per systemd tag, since we can't match on distinct
    # strings, only by using wildcards with a prefix/suffix. We can't prefix
    # these (e.g. with "k8s_node.") since we need to output the records with the
    # distinct tags, and Fluent Bit doesn't yet support modifying the tag (only
    # setting it in the input plugin). We can revise once the feature request
    # (https://github.com/fluent/fluent-bit/issues/293) is fulfilled.
    [FILTER]
        # https://docs.fluentbit.io/manual/filter/record_modifier
        Name    record_modifier
        Match   docker
        Record  logging.googleapis.com/local_resource_id k8s_node.${NODE_NAME}

    [FILTER]
        # https://docs.fluentbit.io/manual/filter/record_modifier
        Name    record_modifier
        Match   kubelet
        Record  logging.googleapis.com/local_resource_id k8s_node.${NODE_NAME}

    [FILTER]
        # https://docs.fluentbit.io/manual/filter/record_modifier
        Name    record_modifier
        Match   node-journal
        Record  logging.googleapis.com/local_resource_id k8s_node.${NODE_NAME}

  filter-kubernetes.conf: |
    [FILTER]
        Name                kubernetes
        Match               k8s_container.*
        Kube_URL            https://kubernetes.default.svc.cluster.local:443
        Merge_Log           Off
        K8S-Logging.Parser  On

  output-fluentd.conf: |
    [OUTPUT]
        Name  forward
        Match *
        Host  ${FLUENTD_IN_FORWARD_SERVICE_HOST}
        Port  ${FLUENTD_IN_FORWARD_SERVICE_PORT}

  parsers.conf: |
    [PARSER]
        Name        docker
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   Off
        # Command      |  Decoder | Field | Optional Action
        # =============|==================|=================
        Decode_Field_As   json       log   do_next
        Decode_Field_As   escaped    log

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: stackdriver-metadata-agent
    cluster-level: "true"
  name: stackdriver-metadata-agent-cluster-level
  namespace: stackdriver-agents
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
  template:
    metadata:
      labels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
    spec:
      containers:
      - env:
        - name: CLUSTER_NAME
          valueFrom:
            configMapKeyRef:
              name: cluster-config
              key: cluster_name
        - name: CLUSTER_LOCATION
          valueFrom:
            configMapKeyRef:
              name: cluster-config
              key: cluster_location
        - name: GOOGLE_APPLICATION_CREDENTIALS
          valueFrom:
            configMapKeyRef:
              name: google-cloud-config
              key: credentials_path
        - name: PROMETHEUS_PORT
          value: "8888"
        args:
        - -logtostderr
        - -v=1
        image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.1
        imagePullPolicy: IfNotPresent
        name: metadata-agent
        resources:
          requests:
            cpu: 40m
            memory: 50Mi
        ports:
        - name: metadata-agent
          containerPort: 8888
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /etc/google-cloud/
          name: google-cloud-config
        - mountPath: /etc/ssl/certs
          name: ssl-certs
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: metadata-agent
      serviceAccountName: metadata-agent
      tolerations:
      - operator: "Exists"
        effect: "NoExecute"
      - operator: "Exists"
        effect: "NoSchedule"
      terminationGracePeriodSeconds: 5
      volumes:
      - configMap:
          defaultMode: 420
          name: google-cloud-config
        name: google-cloud-config
      - hostPath:
          path: /etc/ssl/certs
          type: Directory
        name: ssl-certs
  strategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate

---
